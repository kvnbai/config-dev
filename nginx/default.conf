#
# This config file is independent but the some PHP settings will not be fully
# functional due to its reliance on varnish's ESI.
#
# Comment/Uncomment the configs you needed.
#
# You should look at the following URL's in order to grasp a solid understanding
# of Nginx configuration files in order to fully unleash the power of Nginx.
# https://www.nginx.com/resources/wiki/start/
# https://www.nginx.com/resources/wiki/start/topics/tutorials/config_pitfalls/
# https://wiki.debian.org/Nginx/DirectoryStructure
#
# In most cases, administrators will remove this file from sites-enabled/ and
# leave it as reference inside of sites-available where it will continue to be
# updated by the nginx packaging team.
#
# This file will automatically load configuration files provided by other
# applications, such as Drupal or Wordpress. These applications will be made
# available underneath a path with that package name, such as /drupal8.
#
# Please see /usr/share/doc/nginx-doc/examples/ for more detailed examples.
#
# Note: You should disable gzip for SSL traffic.
# https://bugs.debian.org/773332

# Syntax:  proxy_cache_path path [levels=levels] [use_temp_path=on|off] keys_zone=name:size
#          [inactive=time] [max_size=size] [manager_files=number] [manager_sleep=time]
#          [manager_threshold=time] [loader_files=number] [loader_sleep=time]
#          [loader_threshold=time] [purger=on|off] [purger_files=number] [purger_sleep=time]
#          [purger_threshold=time];
# Default: —
# Context: http
#
# Sets the path and other parameters of a cache. Cache data are stored in files.
# The file name in a cache is a result of applying the MD5 function to the cache
# key. The levels parameter defines hierarchy levels of a cache: from 1 to 3,
# each level accepts values 1 or 2. For example, in the following configuration:
#     proxy_cache_path /data/nginx/cache levels=1:2 keys_zone=one:10m;
#
# file names in a cache will look like this:
#     /data/nginx/cache/c/29/b7f54b2df7773722d382f4809d65029c
#
# A cached response is first written to a temporary file, and then the file is
# renamed. Starting from version 0.8.9, temporary files and the cache can be put
# on different file systems. However, be aware that in this case a file is copied
# across two file systems instead of the cheap renaming operation. It is thus
# recommended that for any given location both cache and a directory holding
# temporary files are put on the same file system. The directory for temporary
# files is set based on the use_temp_path parameter (1.7.10). If this parameter
# is omitted or set to the value on, the directory set by the proxy_temp_path
# directive for the given location will be used. If the value is set to off,
# temporary files will be put directly in the cache directory.
#
# In addition, all active keys and information about data are stored in a
# shared memory zone, whose name and size are configured by the keys_zone
# parameter. One megabyte zone can store about 8 thousand keys.
#
# Cached data that are not accessed during the time specified by the inactive
# parameter get removed from the cache regardless of their freshness.
# By default, inactive is set to 10 minutes.
#
# The special “cache manager” process monitors the maximum cache size set by
# the max_size parameter. When this size is exceeded, it removes the least
# recently used data. The data is removed in iterations configured by
# manager_files, manager_threshold, and manager_sleep parameters (1.11.5).
# During one iteration no more than manager_files items are deleted (by default,
# 100). The duration of one iteration is limited by the manager_threshold 
# parameter (by default, 200 milliseconds). Between iterations, a pause configured
# by the manager_sleep parameter (by default, 50 milliseconds) is made.
#
# A minute after the start the special “cache loader” process is activated.
# It loads information about previously cached data stored on file system into
# a cache zone. The loading is also done in iterations. During one iteration
# no more than loader_files items are loaded (by default, 100). Besides, the
# duration of one iteration is limited by the loader_threshold parameter
# (by default, 200 milliseconds). Between iterations, a pause configured by the
# loader_sleep parameter (by default, 50 milliseconds) is made.
proxy_cache_path /tmp/nginx/ keys_zone=localhostcache:10m loader_threshold=300 loader_files=200;

# Syntax:  upstream name { ... }
# Default: —
# Context: http
#
# Defines a group of servers. Servers can listen on different ports. In addition,
# servers listening on TCP and UNIX-domain sockets can be mixed.
#
# Example:
#
# upstream backend {
#     server backend1.example.com weight=5;
#     server 127.0.0.1:8080       max_fails=3 fail_timeout=30s;
#     server unix:/tmp/backend3;
#
#     server backup1.example.com  backup;
# }
#
# By default, requests are distributed between the servers using a weighted
# round-robin balancing method. In the above example, each 7 requests will
# be distributed as follows: 5 requests go to backend1.example.com and one
# request to each of the second and third servers. If an error occurs during
# communication with a server, the request will be passed to the next server,
# and so on until all of the functioning servers will be tried. If a successful
# response could not be obtained from any of the servers, the client will receive
# the result of the communication with the last server.
#
# Module: NodeJS Loadbalancing
# upstream nodejs {
#     # Load-Balancing Methods:
#     #
#     # - Round Robin
#     #     Requests are distributed evenly across the servers, with server
#     #     weights taken into consideration. This method is used by default
#     #     (there is no directive for enabling it):
#     #     
#     #     upstream backend {
#     #         server backend1.example.com;
#     #         server backend2.example.com;
#     #     }
#     #
#     # - Least Connections
#     #      A request is sent to the server with the least number of active
#     #      connections, again with server weights taken into consideration:
#     #     
#     #     upstream backend {
#     #         least_conn;
#     #         server backend1.example.com;
#     #         server backend2.example.com;
#     #     }
#     #
#     # - IP Hash
#     #     The server to which a request is sent is determined from the client
#     #     IP address. In this case, either the first three octets of the IPv4
#     #     address or the whole IPv6 address are used to calculate the hash
#     #     value. The method guarantees that requests from the same address get
#     #     to the same server unless it is not available.
#     #     
#     #     upstream backend {
#     #         ip_hash;
#     #         server backend1.example.com;
#     #         server backend2.example.com;
#     #     }
#     #
#     #     If one of the servers needs to be temporarily removed from the
#     #     load‑balancing rotation, it can be marked with the down parameter in
#     #     order to preserve the current hashing of client IP addresses.
#     #     Requests that were to be processed by this server are automatically
#     #     sent to the next server in the group:
#     #     
#     #     upstream backend {
#     #         server backend1.example.com;
#     #         server backend2.example.com;
#     #         server backend3.example.com;
#     #     }
#     #
#     # - Generic Hash
#     #     The server to which a request is sent is determined from a user‑defined
#     #     key which can be a text string, variable, or a combination. For example,
#     #     the key may be a paired source IP address and port, or a URI as in this
#     #     example:
#     #     
#     #     upstream backend {
#     #         hash $request_uri consistent;
#     #         server backend1.example.com;
#     #         server backend2.example.com;
#     #     }
#     #
#     #     The optional consistent parameter to the hash directive enables ketama
#     #     consistent‑hash load balancing. Requests are evenly distributed across
#     #     all upstream servers based on the user‑defined hashed key value. If an
#     #     upstream server is added to or removed from an upstream group, only a
#     #     few keys are remapped which minimizes cache misses in the case of
#     #     load‑balancing cache servers or other applications that accumulate state.
#     # ip_hash;
#
#     # Syntax:  server address [parameters];
#     # Default: —
#     # Context: upstream
#     #
#     # Defines the address and other parameters of a server. The address can be
#     # specified as a domain name or IP address, with an optional port, or as a
#     # UNIX-domain socket path specified after the “unix:” prefix. If a port is
#     # not specified, the port 80 is used. A domain name that resolves to several
#     # IP addresses defines multiple servers at once. The following parameters can
#     # be defined:
#     #
#     # - weight=number
#     #     sets the weight of the server, by default, 1.
#     # - max_conns=number
#     #     limits the maximum number of simultaneous active connections to the
#     #     proxied server (1.11.5). Default value is zero, meaning there is no
#     #     limit. If the server group does not reside in the shared memory, the
#     #     limitation works per each worker process.
#     #
#     #     If idle keepalive connections, multiple workers, and the shared memory
#     #     are enabled, the total number of active and idle connections to the 
#     #     proxied server may exceed the max_conns value.
#     #
#     #     Since version 1.5.9 and prior to version 1.11.5, this parameter was
#     #     available as part of our commercial subscription.
#     # - max_fails=number
#     #     sets the number of unsuccessful attempts to communicate with the server
#     #     that should happen in the duration set by the fail_timeout parameter to
#     #     consider the server unavailable for a duration also set by the fail_timeout
#     #     parameter. By default, the number of unsuccessful attempts is set to 1.
#     #     The zero value disables the accounting of attempts. What is considered an
#     #     unsuccessful attempt is defined by the proxy_next_upstream,
#     #     fastcgi_next_upstream, uwsgi_next_upstream, scgi_next_upstream,
#     #     memcached_next_upstream, and grpc_next_upstream directives.
#     # - fail_timeout=time
#     #    sets
#     #         - the time during which the specified number of unsuccessful
#     #           attempts to communicate with the server should happen to consider
#     #           the server unavailable;
#     #         - and the period of time the server will be considered unavailable.
#     #
#     #     By default, the parameter is set to 10 seconds.
#     # - backup
#     #     marks the server as a backup server. It will be passed requests when
#     #     the primary servers are unavailable.
#     # - down
#     #     marks the server as permanently unavailable.
#     server 127.0.0.1:11061 max_fails=3 fail_timeout=5;
#     server 127.0.0.1:11062 max_fails=3 fail_timeout=5;
#     server 127.0.0.1:11063 max_fails=3 fail_timeout=5;
#     server 127.0.0.1:11064 max_fails=3 fail_timeout=5;
#
#     server 127.0.0.1:11065 down;
#     # Only use when all primary servers are down. `ip_hash` balancing doesn't
#     # support this feature.
#     server 127.0.0.1:11066 backup;
#     server 127.0.0.1:11067 backup;
#     server 127.0.0.1:11068 backup;
#     server 127.0.0.1:11069 backup;
#
#     # Syntax:  keepalive connections;
#     # Default: —
#     # Context: upstream
#     #
#     # Activates the cache for connections to upstream servers.
#     # The connections parameter sets the maximum number of idle keepalive
#     # connections to upstream servers that are preserved in the cache of each
#     # worker process. When this number is exceeded, the least recently used
#     # connections are closed.
#     #
#     # It should be particularly noted that the keepalive directive does not
#     # limit the total number of connections to upstream servers that an nginx
#     # worker process can open. The connections parameter should be set to a
#     # number small enough to let upstream servers process new incoming connections
#     # as well.
#     #
#     # For HTTP, the proxy_http_version directive should be set to “1.1” and the
#     # “Connection” header field should be cleared:
#     #
#     #     location /http/ {
#     #         ...
#     #         proxy_http_version 1.1;
#     #         proxy_set_header Connection "";
#     #         ...
#     #     }
#     #
#     # Alternatively, HTTP/1.0 persistent connections can be used by passing the
#     # “Connection: Keep-Alive” header field to an upstream server, though this
#     # method is not recommended.
#     #
#     # For FastCGI servers, it is required to set fastcgi_keep_conn for keepalive
#     # connections to work:
#     #
#     #     location /fastcgi/ {
#     #         ...
#     #         fastcgi_keep_conn on;
#     #         ...
#     #     }
#     #
#     # When using load balancer methods other than the default round-robin method,
#     # it is necessary to activate them before the keepalive directive.
#     keepalive 16;
# }

# Syntax:  server { ... }
# Default: —
# Context: http
#
# Sets configuration for a virtual server. There is no clear separation between
# IP-based (based on the IP address) and name-based (based on the “Host” request
# header field) virtual servers. Instead, the listen directives describe all
# addresses and ports that should accept connections for the server, and the
# server_name directive lists all server names.
#
# Module: Proxy Load-balanced nodejs
# server {
#     # Syntax:  listen address[:port] [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
#     #          listen port [default_server] [ssl] [http2 | spdy] [proxy_protocol] [setfib=number] [fastopen=number] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [ipv6only=on|off] [reuseport] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
#     #          listen unix:path [default_server] [ssl] [http2 | spdy] [proxy_protocol] [backlog=number] [rcvbuf=size] [sndbuf=size] [accept_filter=filter] [deferred] [bind] [so_keepalive=on|off|[keepidle]:[keepintvl]:[keepcnt]];
#     # Default: listen *:80 | *:8000;
#     # Context: server
#     #
#     # Sets the address and port for IP, or the path for a UNIX-domain socket on
#     # which the server will accept requests. Both address and port, or only
#     # address or only port can be specified. An address may also be a hostname,
#     # for example: listen *:8000; listen unix:/var/run/nginx.sock; listen [::]:8000;
#     listen 443 ssl http2;
#
#     # Syntax: server_name name ...;
#     # Default: server_name '';
#     # Context: server
#     # Sets names of a virtual server, for example:
#     #
#     # server {
#     #     server_name example.com www.example.com;
#     # }
#     #
#     # The first name becomes the primary server name.
#     #
#     # Server names can include an asterisk (“*”) replacing the first or last part of a name:
#     #
#     # server {
#     #     server_name example.com *.example.com www.example.*;
#     # }
#     #
#     # Such names are called wildcard names.
#     server_name www.localhost.com;
#
#     # Syntax:  ssl_certificate file;
#     # Default: —
#     # Context: http, server
#     #
#     # Specifies a file with the certificate in the PEM format for the given
#     # virtual server. If intermediate certificates should be specified in
#     # addition to a primary certificate, they should be specified in the same
#     # file in the following order: the primary certificate comes first, then
#     # the intermediate certificates. A secret key in the PEM format may be
#     # placed in the same file.
#     ssl_certificate /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.crt;
#
#     # Syntax:  ssl_password_file file;
#     # Default: —
#     # Context: http, server
#     #
#     # Specifies a file with passphrases for secret keys where each passphrase
#     # is specified on a separate line. Passphrases are tried in turn when loading the key.
#     #
#     # This option is not needed if you use my SSL generator for local development.
#     # Visit: ../certs then execute ./create.sh
#     # ssl_password_file /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.pass;
#
#     # Syntax:  ssl_certificate_key file;
#     # Default: —
#     # Context: http, server
#     #
#     # Specifies a file with the secret key in the PEM format for the given
#     # virtual server.
#     ssl_certificate_key /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.key;
#
#     # Syntax:  ssl_protocols [SSLv2] [SSLv3] [TLSv1] [TLSv1.1] [TLSv1.2] [TLSv1.3];
#     # Default: ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
#     # Context: http, server
#     #
#     # Enables the specified protocols.  The TLSv1.1 and TLSv1.2 parameters
#     # (1.1.13, 1.0.12) work only when OpenSSL 1.0.1 or higher is used. The
#     # TLSv1.3 parameter (1.13.0) works only when OpenSSL 1.1.1 built with
#     # TLSv1.3 support is used.
#     ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
#
#     # Syntax:  ssl_session_cache off | none | [builtin[:size]] [shared:name:size];
#     # Default: ssl_session_cache none;
#     # Context: http, server
#     #
#     # Sets the types and sizes of caches that store session parameters. A cache
#     # can be of any of the following types:
#     #
#     # - off
#     #     the use of a session cache is strictly prohibited: nginx explicitly
#     #     tells a client that sessions may not be reused.
#     # - none
#     #     the use of a session cache is gently disallowed: nginx tells a client
#     #     that sessions may be reused, but does not actually store session
#     #     parameters in the cache.
#     # - builtin
#     #     a cache built in OpenSSL; used by one worker process only. The cache
#     #     size is specified in sessions. If size is not given, it is equal to
#     #     20480 sessions. Use of the built-in cache can cause memory fragmentation.
#     # - shared
#     #     a cache shared between all worker processes. The cache size is
#     #     specified in bytes; one megabyte can store about 4000 sessions. Each
#     #     shared cache should have an arbitrary name. A cache with the same name
#     #     can be used in several virtual servers.
#     #
#     # Both cache types can be used simultaneously, for example:
#     # ssl_session_cache builtin:1000 shared:SSL:10m;
#     #
#     # but using only shared cache without the built-in cache should be more
#     # efficient.
#     ssl_session_cache shared:SSL:1m;
#
#     # Syntax:  ssl_prefer_server_ciphers on | off;
#     # Default: ssl_prefer_server_ciphers off;
#     # Context: http, server
#     #
#     # Specifies that server ciphers should be preferred over client ciphers when
#     # using the SSLv3 and TLS protocols.
#     ssl_prefer_server_ciphers on;
#
#     # Syntax:  ssl_ciphers ciphers;
#     # Default: ssl_ciphers HIGH:!aNULL:!MD5;
#     # Context: http, server
#     #
#     # Specifies the enabled ciphers. The ciphers are specified in the format
#     # understood by the OpenSSL library.
#     ssl_ciphers HIGH:!aNULL:!MD5;
#
#     # Syntax: location [ = | ~ | ~* | ^~ ] uri { ... }
#     #         location @name { ... }
#     # Default: —
#     # Context: server, location
#     #
#     # The matching is performed against a normalized URI, after decoding the
#     # text encoded in the “%XX” form, resolving references to relative path
#     # components “.” and “..”, and possible compression of two or more adjacent
#     # slashes into a single slash.
#     #
#     # A location can either be defined by a prefix string, or by a regular
#     # expression. Regular expressions are specified with the preceding “~*” 
#     # modifier (for case-insensitive matching), or the “~” modifier (for
#     # case-sensitive matching).
#     location / {
#
#         # Syntax:  proxy_set_header field value;
#         # Default: proxy_set_header Host $proxy_host;
#         #          proxy_set_header Connection close;
#         # Context: http, server, location
#         #
#         # Allows redefining or appending fields to the request header passed
#         # to the proxied server. The value can contain text, variables, and
#         # their combinations. These directives are inherited from the previous
#         # level if and only if there are no proxy_set_header directives defined
#         # on the current level. By default, only two fields are redefined.
#         proxy_set_header X-Real-IP $remote_addr;
#         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
#         proxy_set_header X-NginX-Proxy true;
#         proxy_set_header Host $http_host;
#
#         # Syntax:  proxy_pass URL;
#         # Default: —
#         # Context: location, if in location, limit_except
#         #
#         # Sets the protocol and address of a proxied server and an optional URI
#         # to which a location should be mapped. As a protocol, “http” or “https”
#         # can be specified. The address can be specified as a domain name or IP
#         # address, and an optional port:
#         #     proxy_pass http://localhost:8000/uri/
#         #
#         # This can be a docker container service: http://node:3000
#         # If you are using node, and you used a https server make sure that
#         # the protocol is https. For this instance, this is declared in the
#         # load balancer settings above (upsteram).
#         proxy_pass http://nodejs;
#
#         # Syntax:  proxy_ssl_session_reuse on | off;
#         # Default: proxy_ssl_session_reuse on;
#         # Context: http, server, location
#         #
#         # Determines whether SSL sessions can be reused when working with the
#         # proxied server. If the errors “SSL3_GET_FINISHED:digest check failed”
#         # appear in the logs, try disabling session reuse.
#         proxy_ssl_session_reuse on;
#
#         # Syntax:  proxy_redirect default;
#         #          proxy_redirect off;
#         #          proxy_redirect redirect replacement;
#         # Default: proxy_redirect default;
#         # Context: http, server, location
#         #
#         # Sets the text that should be changed in the “Location” and “Refresh”
#         # header fields of a proxied server response. Suppose a proxied server
#         # returned the header field “Location: http://localhost:8000/two/some/uri/”.
#         # The directive proxy_redirect http://localhost:8000/two/ http://frontend/one/;
#         # will rewrite this string to “Location: http://frontend/one/some/uri/”.
#         #
#         # A server name may be omitted in the replacement string:
#         #
#         # proxy_redirect http://localhost:8000/two/ /;
#         # then the primary server’s name and port, if different from 80, will
#         # be inserted
#         # proxy_redirect off;
#
#         # Syntax:  proxy_cache zone | off;
#         # Default: proxy_cache off;
#         # Context: http, server, location
#         #
#         # Defines a shared memory zone used for caching. The same zone can be used
#         # in several places. Parameter value can contain variables (1.7.9). The
#         # off parameter disables caching inherited from the previous configuration
#         # level.
#         #
#         # Declared above.
#         proxy_cache localhostcache;
#
#         # Syntax:  proxy_cache_key string;
#         # Default: proxy_cache_key $scheme$proxy_host$request_uri;
#         # Context: http, server, location
#         #
#         # Defines a key for caching, for example
#         #     proxy_cache_key "$host$request_uri $cookie_user";
#         # By default, the directive’s value is close to the string
#         #     proxy_cache_key $scheme$proxy_host$uri$is_args$args;
#         proxy_cache_key "$host$request_uri$cookie_user";
#
#         # Syntax:  proxy_cache_min_uses number;
#         # Default: proxy_cache_min_uses 1;
#         # Context: http, server, location
#         #
#         # Sets the number of requests after which the response will be cached.
#         proxy_cache_min_uses 5;
#
#         # Syntax:  proxy_cache_methods GET | HEAD | POST ...;
#         # Default: proxy_cache_methods GET HEAD;
#         # Context: http, server, location
#         #
#         # If the client request method is listed in this directive then the 
#         # response will be cached. “GET” and “HEAD” methods are always added 
#         # to the list, though it is recommended to specify them explicitly. 
#         # See also the proxy_no_cache directive.
#         proxy_cache_methods GET HEAD;
#
#         # Syntax:  proxy_cache_valid [code ...] time;
#         # Default: —
#         # Context: http, server, location
#         #
#         # Sets caching time for different response codes. For example, the 
#         # following directives:
#         #
#         #     proxy_cache_valid 200 302 10m;
#         #     proxy_cache_valid 404      1m;
#         #
#         # set 10 minutes of caching for responses with codes 200 and 302 and
#         # 1 minute for responses with code 404.
#         #
#         # If only caching time is specified
#         #
#         #     proxy_cache_valid 5m;
#         #
#         # then only 200, 301, and 302 responses are cached.
#         #
#         # In addition, the any parameter can be specified to cache any responses:
#         #
#         #     proxy_cache_valid 200 302 10m;
#         #     proxy_cache_valid 301      1h;
#         #     proxy_cache_valid any      1m;
#         #
#         # Parameters of caching can also be set directly in the response header.
#         # This has higher priority than setting of caching time using the directive.
#         #
#         # - The “X-Accel-Expires” header field sets caching time of a response 
#         #   in seconds. The zero value disables caching for a response. If the 
#         #   value starts with the @ prefix, it sets an absolute time in seconds 
#         #   since Epoch, up to which the response may be cached.
#         # - If the header does not include the “X-Accel-Expires” field, parameters
#         #   of caching may be set in the header fields “Expires” or “Cache-Control”.
#         # - If the header includes the “Set-Cookie” field, such a response will not
#         #   be cached.
#         # - If the header includes the “Vary” field with the special value “*”, 
#         #   such a response will not be cached. If the header includes the “Vary” 
#         #   field with another value, such a response will be cached taking into 
#         #   account the corresponding request header fields.
#         #
#         # Processing of one or more of these response header fields can be disabled
#         # using the proxy_ignore_headers directive.
#         proxy_cache_valid 200 1s;
#
#         # Syntax:  proxy_cache_lock on | off;
#         # Default: proxy_cache_lock off;
#         # Context: http, server, location
#         #
#         # When enabled, only one request at a time will be allowed to populate a
#         # new cache element identified according to the proxy_cache_key directive
#         # by passing a request to a proxied server. Other requests of the same
#         # cache element will either wait for a response to appear in the cache
#         # or the cache lock for this element to be released, up to the time set
#         # by the proxy_cache_lock_timeout directive
#         proxy_cache_lock on;
#
#         # Syntax:  proxy_cache_use_stale error | timeout | invalid_header |
#         #          updating | http_500 | http_502 | http_503 | http_504 | http_403 |
#         #          http_404 | http_429 | off ...;
#         # Default: proxy_cache_use_stale off;
#         # Context: http, server, location
#         #
#         # Determines in which cases a stale cached response can be used during
#         # communication with the proxied server. The directive’s parameters match
#         # the parameters of the proxy_next_upstream directive.
#         #
#         # The error parameter also permits using a stale cached response if a
#         # proxied server to process a request cannot be selected.
#         #
#         # Additionally, the updating parameter permits using a stale cached
#         # response if it is currently being updated. This allows minimizing the
#         # number of accesses to proxied servers when updating cached data.
#         #
#         # Using a stale cached response can also be enabled directly in the
#         # response header for a specified number of seconds after the response
#         # became stale. This has lower priority than using the directive parameters.
#         #
#         # The “stale-while-revalidate” extension of the “Cache-Control” header 
#         # field permits using a stale cached response if it is currently being
#         # updated.
#         #
#         # The “stale-if-error” extension of the “Cache-Control” header field 
#         # permits using a stale cached response in case of an error.
#         #
#         # To minimize the number of accesses to proxied servers when populating
#         # a new cache element, the proxy_cache_lock directive can be used.
#         #
#         # Configures NGINX to serve stale (currently cached) content while a
#         # cached entry is being updated:
#         proxy_cache_use_stale updating;
#     }
#
#     # Create proxy for websockets (points to the socket namespace)
#     location /socket {
#         # Syntax:  proxy_http_version 1.0 | 1.1;
#         # Default: proxy_http_version 1.0;
#         # Context: http, server, location
#         #
#         # Sets the HTTP protocol version for proxying. By default, version 1.0
#         # is used. Version 1.1 is recommended for use with keepalive connections
#         # and NTLM authentication.
#         #
#         # Not really needed here but the default will be 1.0
#         proxy_http_version 1.1;
#
#         # Both are required for websockets because native ws/s connections are
#         # upgraded http/s. If your sockets works without this it probably
#         # downgrades to long-polling/polling.
#         proxy_set_header Upgrade $http_upgrade;
#         proxy_set_header Connection "upgrade";
#
#         # socket namespace
#         proxy_pass http://nodejs/socket;
#     }
# }

# Module: NodeJS basic
# server {
#     listen 443 ssl http2;
#     server_name www.localhost.com;
#
#     ssl_certificate /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.crt;
#     ssl_certificate_key /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.key;
#     ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
#     ssl_session_cache shared:SSL:1m;
#     ssl_prefer_server_ciphers on;
#     ssl_ciphers HIGH:!aNULL:!MD5;
#
#     location / {
#         proxy_set_header X-Real-IP $remote_addr;
#         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
#         proxy_set_header X-NginX-Proxy true;
#         proxy_set_header Host $http_host;
#         proxy_pass http://127.0.0.1:11060;
#         proxy_ssl_session_reuse on;
#         proxy_cache localhostcache;
#         proxy_cache_key "$host$request_uri$cookie_user";
#         proxy_cache_min_uses 5;
#         proxy_cache_methods GET HEAD;
#         proxy_cache_valid 200 1s;
#         proxy_cache_lock on;
#         proxy_cache_use_stale updating;
#     }
#
#     location /socket {
#         proxy_http_version 1.1;
#         proxy_pass http://127.0.0.1:11060/socket;
#     }
# }

# A different domain that will serve assets instead of hitting the nodejs
# servers within the load balancer.
#
# Module: NodeJS assets
# server {
#     listen 443 ssl http2;
#     server_name assets.localhost.com;
#
#     # Syntax:  root path;
#     # Default: root html;
#     # Context: http, server, location, if in location
#     #
#     # Sets the root directory for requests. For example, with the following
#     # configuration:
#     #
#     # location /i/ {
#     #     root /data/w3;
#     # }
#     #
#     # The /data/w3/i/top.gif file will be sent in response to the “/i/top.gif”
#     # request.
#     #
#     # The path value can contain variables, except $document_root and $realpath_root.
#     #
#     # A path to the file is constructed by merely adding a URI to the value of
#     # the root directive. If a URI has to be modified, the alias directive
#     # should be used.
#     root /var/www/workspace/config-desktop/dev/nodejs/app/assets;
#
#     # Syntax:  index file ...;
#     # Default: index index.html;
#     # Context: http, server, location
#     #
#     # index index.html index.htm index.nginx-debian.html index.php;
#     #
#     # Defines files that will be used as an index. The file name can contain
#     # variables. Files are checked in the specified order. The last element
#     # of the list can be a file with an absolute path. Example:
#     #
#     # index index.$geo.html index.0.html /index.html;
#     # It should be noted that using an index file causes an internal redirect,
#     # and the request can be processed in a different location. For example,
#     # with the following configuration:
#     #
#     # location = / {
#     #      index index.html;
#     # }
#     #
#     # location / {
#     #     ...
#     # }
#     # a “/” request will actually be processed in the second location as
#     # “/index.html”.
#     index index.php index.html index.htm index.nginx-debian.html;
#
#     ssl_certificate /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.crt;
#     ssl_certificate_key /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.key;
#     ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
#     ssl_session_cache shared:SSL:1m;
#     ssl_prefer_server_ciphers on;
#     ssl_ciphers HIGH:!aNULL:!MD5;
#
#     # Don't cache JS files. Created just for demo and development.
#     location /js {
#
#         # Syntax:  add_header name value [always];
#         # Default: —
#         # Context: http, server, location, if in location
#         #
#         # Adds the specified field to a response header provided that the 
#         # response code equals 200, 201, 204, 206, 301, 302, 303, 304, 307, or 308.  
#         # The value can contain variables.
#         #
#         # There could be several add_header directives. These directives are
#         # inherited from the previous level if and only if there are no add_header
#         # directives defined on the current level.
#         #
#         # If the always parameter is specified, the header field will be added
#         # regardless of the response code.
#         add_header Last-Modified $date_gmt;
#         add_header Cache-Control 'no-store, no-cache, must-revalidate, proxy-revalidate, max-age=0';
#
#         # Syntax:  if_modified_since off | exact | before;
#         # Default: if_modified_since exact;
#         # Context: http, server, location
#         #
#         # Specifies how to compare modification time of a response with the
#         # time in the “If-Modified-Since” request header field:
#         #
#         # - off
#         #     the “If-Modified-Since” request header field is ignored (0.7.34);
#         # - exact
#         #     exact match;
#         # - before
#         #     modification time of a response is less than or equal to the time 
#         #     in the “If-Modified-Since” request header field.
#         if_modified_since off;
#
#         # Syntax:  etag on | off;
#         # Default: etag on;
#         # Context: http, server, location
#         #
#         # Enables or disables automatic generation of the “ETag” response header
#         # field for static resources.
#         etag off;
#
#         # Syntax:  expires [modified] time;
#         #          expires epoch | max | off;
#         # Default: expires off;
#         # Context: http, server, location, if in location
#         #
#         # Enables or disables adding or modifying the “Expires” and “Cache-Control”
#         # response header fields provided that the response code equals 200,
#         # 201, 204, 206, 301, 302, 303, 304, 307, or 308. The parameter can be
#         # a positive or negative time.
#         #
#         # The time in the “Expires” field is computed as a sum of the current
#         # time and time specified in the directive. If the modified parameter
#         # is used then the time is computed as a sum of the file’s modification
#         # time and the time specified in the directive.
#         #
#         # In addition, it is possible to specify a time of day using the “@” prefix:
#         #     expires @15h30m;
#         #
#         # The epoch parameter corresponds to the absolute time “Thu, 01 Jan 1970
#         # 00:00:01 GMT”. The contents of the “Cache-Control” field depends on
#         # the sign of the specified time:
#         #
#         #     - time is negative — “Cache-Control: no-cache”.
#         #     - time is positive or zero — “Cache-Control: max-age=t”, where t
#         #       is a time specified in the directive, in seconds.
#         #
#         # The max parameter sets “Expires” to the value “Thu, 31 Dec 2037 23:55:55
#         # GMT”, and “Cache-Control” to 10 years.
#         #
#         # The off parameter disables adding or modifying the “Expires” and
#         # “Cache-Control” response header fields.
#         #
#         # The last parameter value can contain variables:
#         # map $sent_http_content_type $expires {
#         #     default         off;
#         #     application/pdf 42d;
#         #     ~image/         max;
#         # }
#         #
#         # expires $expires;
#         expires off;
#     }
# }

# Will be listened by varnish then passed to nginx again.
#
# Module: PHP proxy for varnish
# server {
#     listen 80;
#     server_name www.localhost.com;
#     root /var/www/workspace/config-desktop/dev/php/app;
#     index index.php;
#
#     location /info {
#        # Route /info to info.php
#         try_files $uri /info.php;
#     }
#
#     location ~ ^/(nocache|10s-cache|20s-cache) {
#         try_files $uri /datetime.php;
#     }
#
#     # PHP-FPM status endpoint
#     location = /status {
#         access_log off;
#         allow 127.0.0.1;
#         deny all;
#         include fastcgi_params;
#         fastcgi_pass 127.0.0.1:9000;
#         fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
#     }
#
#     # PHP-FPM ping endpoint
#     location = /ping {
#         access_log off;
#         allow 127.0.0.1;
#         deny all;
#         include fastcgi_params;
#         fastcgi_pass 127.0.0.1:9000;
#         fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
#     }
#
#     location / {
#        # First attempt to serve request as file, then
#        # as directory, then fall back to displaying a 404.
#         try_files $uri $uri/ =404;
#     }
#
#     # pass PHP scripts to FastCGI server
#     location ~ \.php$ {
#         include fastcgi_params;
#
#         # Syntax:  fastcgi_split_path_info regex;
#         # Default: —
#         # Context: location
#         #
#         # Defines a regular expression that captures a value for the
#         # $fastcgi_path_info variable. The regular expression should have
#         # two captures: the first becomes a value of the $fastcgi_script_name
#         # variable, the second becomes a value of the $fastcgi_path_info variable.
#         # For example, with these settings:
#         #
#         # location ~ ^(.+\.php)(.*)$ {
#         #     fastcgi_split_path_info       ^(.+\.php)(.*)$;
#         #     fastcgi_param SCRIPT_FILENAME /path/to/php$fastcgi_script_name;
#         #     fastcgi_param PATH_INFO       $fastcgi_path_info;
#         # }
#         #
#         # and the “/show.php/article/0001” request, the SCRIPT_FILENAME parameter
#         # will be equal to “/path/to/php/show.php”, and the PATH_INFO parameter
#         # will be equal to “/article/0001
#         fastcgi_split_path_info ^(.+\.php)(/.*)$;
#
#         # optionally set the value of the environment variables used in the application
#         # fastcgi_param APP_ENV prod;
#         # fastcgi_param APP_SECRET <app-secret-id>;
#         # fastcgi_param DATABASE_URL "mysql://db_user:db_pass@host:3306/db_name";
#
#         # When you are using symlinks to link the document root to the
#         # current version of your application, you should pass the real
#         # application path instead of the path to the symlink to PHP
#         # FPM.
#         # Otherwise, PHP's OPcache may not properly detect changes to
#         # your PHP files (see https://github.com/zendtech/ZendOptimizerPlus/issues/126
#         # for more information).
#         fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;
#         fastcgi_param DOCUMENT_ROOT $realpath_root;
#
#         # Syntax:  fastcgi_pass address;
#         # Default: —
#         # Context: location, if in location
#         #
#         # Sets the address of a FastCGI server. The address can be specified
#         # as a domain name or IP address, and a port:
#         #     fastcgi_pass localhost:9000;
#         # or as a UNIX-domain socket path:
#         #     fastcgi_pass unix:/tmp/fastcgi.socket;
#         #
#         # With php-fpm (or other unix sockets):
#         # fastcgi_pass unix:/run/php/php7.2-fpm.sock;
#
#         # With php-cgi (or other tcp sockets):
#         fastcgi_pass 127.0.0.1:9000;
#
#         # Prevents URIs that include the front controller. This will 404:
#         # http://domain.tld/index.php/some-path
#         # Remove the internal directive to allow URIs like this
#         internal;
#     }
#
#     # deny access to .htaccess files, if Apache's document root
#     # concurs with nginx's one
#     location ~ /\.ht {
#         deny all;
#     }
# }

# Will listen to varnish port then encrypt SSL.
#
# Module: PHP SSL encrypt varnish
# server {
#     listen 443 ssl http2;
#     server_name www.localhost.com;
#
#     ssl_certificate /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.crt;
#     ssl_certificate_key /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.key;
#     ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
#     ssl_session_cache shared:SSL:1m;
#     ssl_prefer_server_ciphers on;
#     ssl_ciphers HIGH:!aNULL:!MD5;
#
#     location / {
#         proxy_set_header X-Real-IP $remote_addr;
#         proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
#         proxy_set_header X-NginX-Proxy true;
#         proxy_set_header Host $http_host;
#         proxy_pass http://localhost:6081;
#         proxy_ssl_session_reuse on;
#         proxy_redirect off;
#     }
# }

# Module: PHP basic
server {
    listen 443 ssl http2;
    server_name www.localhost.com;
    root /var/www/workspace/config-desktop/dev/php/app;
    index index.php;

    ssl_certificate /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.crt;
    ssl_certificate_key /var/www/workspace/config-desktop/dev/certificate/www.localhost.com.key;
    ssl_protocols TLSv1 TLSv1.1 TLSv1.2;
    ssl_session_cache shared:SSL:1m;
    ssl_prefer_server_ciphers on;
    ssl_ciphers HIGH:!aNULL:!MD5;

    location /info {
        try_files $uri /info.php;
    }

    location ~ ^/(nocache|10s-cache|20s-cache) {
        try_files $uri /datetime.php;
    }

    location = /status {
        access_log off;
        allow 127.0.0.1;
        deny all;
        include fastcgi_params;
        fastcgi_pass 127.0.0.1:9000;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    }

    location = /ping {
        access_log off;
        allow 127.0.0.1;
        deny all;
        include fastcgi_params;
        fastcgi_pass 127.0.0.1:9000;
        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
    }

    location / {
        try_files $uri $uri/ =404;
    }

    location ~ \.php$ {
        include fastcgi_params;
        fastcgi_split_path_info ^(.+\.php)(/.*)$;
        fastcgi_param SCRIPT_FILENAME $realpath_root$fastcgi_script_name;
        fastcgi_param DOCUMENT_ROOT $realpath_root;
        fastcgi_pass 127.0.0.1:9000;
        internal;
    }

    location ~ /\.ht {
        deny all;
    }
}
